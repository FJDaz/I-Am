# Plan d'Action Complet : G√©n√©raliser I-Amiens √† Tout le Site

**Date :** 2025-01-XX  
**Inclut :** Optimisations performance (Claude Haiku, cache, RAG)

---

## Phase 1 : Refactoriser les Modules de D√©couverte

‚úÖ **Automatisable :**
- Cr√©er `tools/discover_urls.py` avec classe `URLDiscoverer`
- Modifier `tools/rebuild_corpus.py` pour utiliser `URLDiscoverer`

---

## Phase 2 : Configuration Multi-Sections

‚úÖ **Automatisable :**
- Cr√©er `ML/data/site_sections.json`
- Cr√©er `tools/crawl_site_generalized.py`

---

## Phase 3 : G√©n√©raliser le Scraping Dynamique

‚úÖ **Automatisable :**
- Renommer `ML/scripts/Audit_Scrap_enfance.py` ‚Üí `crawl_dynamic.py`
- G√©n√©raliser pour toutes sections

---

## Phase 4 : R√©g√©n√©ration Embeddings et Index RAG

‚úÖ **Automatisable :**
- Modifier `ML/embed_corpus.py` pour corpus g√©n√©ralis√©
- V√©rifier performance Whoosh (code de test)

‚ö†Ô∏è **N√©cessite validation :**
- Tester performance avec corpus plus grand

---

## Phase 5 : Adaptation Syst√®me RAG

‚úÖ **Automatisable :**
- Modifier prompt syst√®me (g√©n√©raliser "Amiens Enfance")
- Adapter chemins embeddings (d√©tection automatique)
- Cr√©er structure lexiques multi-sections
- Adapter `load_structured_data()` (chargement conditionnel)

---

## Phase 6 : Optimisation Performance et Latence

‚úÖ **Automatisable :**
- Cr√©er `Backend/cache.py` (cache m√©moire)
- Int√©grer cache dans `rag_assistant_endpoint()`
- Optimiser recherche RAG (r√©duire top_k, cache embeddings)
- Ajouter support Claude Haiku (variable d'environnement)

‚ö†Ô∏è **N√©cessite d√©cision :**
- Tester Claude Haiku vs Sonnet et d√©cider
- Valider que cache fonctionne correctement

---

## Phase 7 : Tests et Validation

‚ùå **N√©cessite intervention manuelle :**
- Test r√©gression Enfance
- Test nouvelles sections (Jeunesse, etc.)
- Test syst√®me RAG complet
- Validation qualit√© r√©ponses

---

## Phase 8 : Documentation

‚úÖ **Automatisable :**
- Cr√©er `docs/tutos/GUIDE_GENERALISATION_SITE.md`
- Mettre √† jour documentation strat√©gies

---

## üöÄ Ce que je peux lancer maintenant

### Fichiers √† cr√©er (100% automatique) :
1. ‚úÖ `tools/discover_urls.py` - Module d√©couverte URLs
2. ‚úÖ `tools/crawl_site_generalized.py` - Crawler g√©n√©ralis√©
3. ‚úÖ `ML/data/site_sections.json` - Configuration sections
4. ‚úÖ `Backend/cache.py` - Cache m√©moire
5. ‚úÖ `ML/scripts/crawl_dynamic.py` - Scraping dynamique g√©n√©ralis√©
6. ‚úÖ `docs/tutos/GUIDE_GENERALISATION_SITE.md` - Guide utilisateur

### Fichiers √† modifier (100% automatique) :
1. ‚úÖ `tools/rebuild_corpus.py` - Utiliser URLDiscoverer
2. ‚úÖ `ML/embed_corpus.py` - Support corpus g√©n√©ralis√©
3. ‚úÖ `Backend/rag_assistant_server.py` - Prompt, chemins, cache, Haiku
4. ‚úÖ Documentation existante

### Ce qui n√©cessite votre intervention :
1. ‚ö†Ô∏è Tester et valider (apr√®s cr√©ation fichiers)
2. ‚ö†Ô∏è Activer sections souhait√©es dans `site_sections.json`
3. ‚ö†Ô∏è D√©cider Claude Haiku vs Sonnet (apr√®s tests)
4. ‚ö†Ô∏è D√©ployer sur Railway

---

## üí° Recommandation

**Je peux cr√©er TOUS les fichiers de code maintenant** (environ 15-20 fichiers/modifications).

**Vous devrez ensuite :**
- Tester le crawl sur Enfance
- Activer les sections souhait√©es
- Tester Claude Haiku
- Valider et d√©ployer

**Souhaitez-vous que je commence maintenant ?**

---

**Derni√®re mise √† jour :** 2025-01-XX

