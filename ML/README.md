# ğŸ¤– ML - PrÃ©paration des DonnÃ©es RAG

**Dossier :** `ML/`  
**Contenu :** Fichiers liÃ©s Ã  la prÃ©paration et au traitement des donnÃ©es RAG

---

## ğŸ“ Structure

```
ML/
â”œâ”€â”€ data/                       # DonnÃ©es RAG (corpus, embeddings, metadata)
â”‚   â”œâ”€â”€ corpus_segments.json   # Corpus segments (utilisÃ© par Backend)
â”‚   â”œâ”€â”€ corpus_embeddings.npy  # Embeddings NumPy (utilisÃ© par Backend)
â”‚   â”œâ”€â”€ corpus_metadata.json   # Metadata corpus (utilisÃ© par Backend)
â”‚   â”œâ”€â”€ rpe_contacts.json      # Contacts RPE
â”‚   â”œâ”€â”€ lieux_importants.json  # Lieux importants
â”‚   â”œâ”€â”€ tarifs_2024_2025.json  # Tableaux tarifs
â”‚   â”œâ”€â”€ ecoles_amiens.json     # Ã‰coles Amiens
â”‚   â””â”€â”€ raw/                   # PDFs sources
â”‚       â”œâ”€â”€ COUPON+INSCRIPTION*.pdf
â”‚       â”œâ”€â”€ LISTE+ALSH+ETE+2025.pdf
â”‚       â””â”€â”€ menus/
â”‚
â”œâ”€â”€ download_amiens_enfance/   # DonnÃ©es scrappÃ©es (HTML/TXT)
â”‚   â””â”€â”€ [374 fichiers HTML/TXT scrappÃ©s du site]
â”‚
â”œâ”€â”€ build_corpus_segments.py   # Construction corpus segments
â”œâ”€â”€ embed_corpus.py            # GÃ©nÃ©ration embeddings
â”œâ”€â”€ extract_pdfs.py            # Extraction PDFs
â””â”€â”€ chunks_*.json              # Chunks intermÃ©diaires
```

---

## ğŸ“‹ Contenu par CatÃ©gorie

### DonnÃ©es RAG (`data/`)

**Fichiers utilisÃ©s par le Backend :**

- **`corpus_segments.json`** - Corpus segments RAG
  - Format : JSON avec segments numÃ©rotÃ©s
  - UtilisÃ© par : Backend RAG System (Whoosh + embeddings)

- **`corpus_embeddings.npy`** - Embeddings NumPy
  - Format : NumPy array (numpy.ndarray)
  - ModÃ¨le : `sentence-transformers/all-MiniLM-L6-v2`
  - GÃ©nÃ©rÃ© par : `embed_corpus.py`

- **`corpus_metadata.json`** - Metadata corpus
  - Format : JSON avec mÃ©tadonnÃ©es (label, url, etc.)
  - UtilisÃ© avec : `corpus_embeddings.npy`

**DonnÃ©es structurÃ©es :**

- **`rpe_contacts.json`** - Contacts RPE (Relais Petite Enfance)
- **`lieux_importants.json`** - Lieux importants (Ã©coles, structures)
- **`tarifs_2024_2025.json`** - Tableaux tarifs (crÃ¨ches, centres de loisirs)
- **`ecoles_amiens.json`** - Ã‰coles Amiens (adresses, contacts)

**Sources brutes :**

- **`raw/`** - PDFs sources
  - Documents d'inscription
  - Menus
  - Tarifs et synoptiques

### DonnÃ©es ScrappÃ©es (`download_amiens_enfance/`)

**Contenu :** 374 fichiers HTML/TXT scrappÃ©s du site "Vivre Ã  Amiens - Enfance"
- Pages HTML complÃ¨tes
- Extractions texte (.txt)
- UtilisÃ© pour construire le corpus RAG

### Scripts de PrÃ©paration

- **`build_corpus_segments.py`** - Construction corpus segments
  - Lit les donnÃ©es scrappÃ©es
  - DÃ©coupe en segments
  - GÃ©nÃ¨re `corpus_segments.json`

- **`embed_corpus.py`** - GÃ©nÃ©ration embeddings
  - Lit `corpus_segments.json`
  - GÃ©nÃ¨re embeddings avec sentence-transformers
  - Exporte `corpus_embeddings.npy` et `corpus_metadata.json`

- **`extract_pdfs.py`** - Extraction PDFs
  - Lit les PDFs dans `data/raw/`
  - Extrait le texte
  - GÃ©nÃ¨re fichiers structurÃ©s

### Chunks IntermÃ©diaires (`chunks/`)

**Fichiers intermÃ©diaires de traitement :**
- `chunks/chunks_enfance.json` - Chunks bruts
- `chunks/chunks_enfance_clean.json` - Chunks nettoyÃ©s
- `chunks/chunks_enfance_min.json` - Chunks minimisÃ©s
- `chunks/chunks_enfance_final.json` - Chunks finaux
- `chunks/chunks_enfance.jsonl` - Format JSONL

**Pourquoi dans ML/ ?** Ces fichiers sont des **donnÃ©es intermÃ©diaires** de prÃ©paration du corpus RAG. Ils font partie du workflow ML (extraction â†’ chunks â†’ corpus â†’ embeddings) et sont stockÃ©s dans `ML/chunks/` car ils ne sont pas utilisÃ©s directement par le Backend (qui utilise `data/corpus_segments.json`).

### Scripts de PrÃ©paration (`scripts/`)

**Scripts de scraping et audit :**
- `scripts/# crawler_respectueux.py` - Crawler respectueux (commentÃ©)
- `scripts/# audit_dynamiques.py` - Audit dynamique (commentÃ©)
- `scripts/# mvp_chunks_cursor.py` - MVP chunks (commentÃ©)
- `scripts/audit_enfance_online.py` - Audit en ligne des pages Enfance
- `scripts/Audit_Scrap_enfance.py` - Audit et scraping dynamique
- `scripts/update_chunks_from_download.py` - Mise Ã  jour chunks depuis download

**Note :** Les fichiers avec `#` au dÃ©but sont commentÃ©s/ignorÃ©s mais conservÃ©s pour rÃ©fÃ©rence.

---

## ğŸ› ï¸ Usage

### Construire le Corpus

```bash
cd ML
python build_corpus_segments.py
```

**RÃ©sultat :** GÃ©nÃ¨re `data/corpus_segments.json`

### GÃ©nÃ©rer les Embeddings

```bash
cd ML
python embed_corpus.py
```

**RÃ©sultat :** 
- GÃ©nÃ¨re `data/corpus_embeddings.npy`
- GÃ©nÃ¨re `data/corpus_metadata.json`

### Extraire les PDFs

```bash
cd ML
python extract_pdfs.py
```

**RÃ©sultat :** Extrait texte des PDFs dans `data/raw/`

---

## ğŸ”„ Workflow ML

```
1. Scraper site Amiens Enfance
   â†“
2. Extraire PDFs (extract_pdfs.py)
   â†“
3. Construire corpus segments (build_corpus_segments.py)
   â†“
4. GÃ©nÃ©rer embeddings (embed_corpus.py)
   â†“
5. IntÃ©grer dans Backend (Backend/rag_assistant_server.py)
```

---

## ğŸ“ Notes

### DiffÃ©rence avec bergsonAndFriends

**bergsonAndFriends :**
- ML/ contient fine-tuning de modÃ¨les (LoRA, adapters)
- Prompts systÃ¨me pour les modÃ¨les

**I-Amiens :**
- ML/ contient prÃ©paration donnÃ©es RAG (pas de fine-tuning)
- Pas de prompts systÃ¨me (utilise Claude API externe)
- Focus sur corpus, embeddings, donnÃ©es structurÃ©es

### Utilisation par le Backend

Les fichiers dans `ML/data/` sont utilisÃ©s par :
- **Backend/rag_assistant_server.py** - Charge embeddings, metadata, donnÃ©es structurÃ©es
- **Backend/chrome-extension-v2/** - Charge `corpus_segments.json` localement

---

## ğŸ”— Liens

- **Backend :** `../Backend/`
- **Documentation :** `../docs/`
- **RAG System :** `../docs/references/segments-rag.md`
- **Stack technique :** `../docs/references/STACK_TECHNIQUE_I_AMIENS.md`

